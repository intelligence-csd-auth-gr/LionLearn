{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LioNets: Turbofan Engine Degradation Simulation Dataset with Neural Networks\n",
    "\n",
    "In this notebook, we present how LioNets can be applied in predictive models using time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from math import sqrt, exp, log\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score, balanced_accuracy_score, accuracy_score\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, TimeDistributed, RepeatVector,Flatten, Input, Dropout, LSTM, concatenate, Reshape, Conv1D, GlobalMaxPool1D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from lionets import LioNets\n",
    "from altruist.altruist import Altruist\n",
    "from utilities.evaluation import Evaluation\n",
    "from utilities.load_dataset import Load_Dataset\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from innvestigate.utils.keras import checks\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load and clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, feature_names = Load_Dataset.load_data_turbofan(False)\n",
    "\n",
    "fm1_train = fm['FaultMode1']['df_train']\n",
    "fm1_train_target = fm1_train['RUL'].values\n",
    "fm1_test= fm['FaultMode1']['df_test']\n",
    "fm1_test_target = fm1_test['RUL'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dropping some unecessary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_train = fm1_train.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])\n",
    "LSTM_test = fm1_test.drop(columns=['t', 'os_1', 'os_2', 'os_3', 's_01', 's_05', 's_06', 's_10', 's_16', 's_18', 's_19', 's_22', 's_23', 's_24', 's_25', 's_26'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We collect the different units, in order to the next steps to create time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_units = set(LSTM_train['u'].values)\n",
    "test_units = set(LSTM_test['u'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are scaling our data per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['s_02', 's_03', 's_04', 's_07', 's_08', 's_09', 's_11', 's_12',\n",
    "            's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "scalers = {}\n",
    "for column in sensors:\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    LSTM_train[column] = scaler.fit_transform(LSTM_train[column].values.reshape(-1,1))\n",
    "    LSTM_test[column] = scaler.transform(LSTM_test[column].values.reshape(-1,1))\n",
    "    scalers[column] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create time windows with a specific size. In this example, we create time windows of 50 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_scalers = {}\n",
    "window = 50\n",
    "temp_LSTM_x_train = []\n",
    "LSTM_y_train = []\n",
    "for unit in train_units:\n",
    "    temp_unit = LSTM_train[LSTM_train['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_train[LSTM_train['u']==unit]['RUL'].values\n",
    "    \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_train.append(np.array(temp_instance))\n",
    "        LSTM_y_train.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_train = np.array(LSTM_y_train)\n",
    "LSTM_x_train = np.array(temp_LSTM_x_train)\n",
    "\n",
    "temp_LSTM_x_test = []\n",
    "LSTM_y_test = []\n",
    "for unit in test_units:\n",
    "    temp_unit = LSTM_test[LSTM_test['u']==unit].drop(columns=['u','RUL']).values\n",
    "    temp_unit_RUL = LSTM_test[LSTM_test['u']==unit]['RUL'].values\n",
    "        \n",
    "    for i in range(len(temp_unit) - window + 1):#elekse edw an len temp_unit - window > 0\n",
    "        temp_instance = []\n",
    "        for j in range(window):\n",
    "            temp_instance.append(temp_unit[i+j])\n",
    "        temp_LSTM_x_test.append(np.array(temp_instance))\n",
    "        LSTM_y_test.append(temp_unit_RUL[i+window-1])\n",
    "LSTM_y_test = np.array(LSTM_y_test)\n",
    "LSTM_x_test = np.array(temp_LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many train, test instances we have. These are changing regarding the time window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_x_train.shape, LSTM_x_test.shape, LSTM_y_train.shape, LSTM_y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we scale our target data, in order to train our models faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_LSTM_y_train = [[i] for i in LSTM_y_train]\n",
    "temp_LSTM_y_test = [[i] for i in LSTM_y_test]\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(temp_LSTM_y_train)\n",
    "temp_LSTM_y_train = target_scaler.transform(temp_LSTM_y_train)\n",
    "temp_LSTM_y_test = target_scaler.transform(temp_LSTM_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We need a rmse loss function too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build our predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = fm1_train.columns\n",
    "encoder_input = Input(shape=(LSTM_x_train[0].shape))\n",
    "\n",
    "encoder_x = LSTM(units=80, return_sequences=True, activation='tanh')(encoder_input)\n",
    "encoder_x = Dropout(0.7)(encoder_x)\n",
    "encoder_x = LSTM(units=40, return_sequences=False, activation='tanh')(encoder_x)\n",
    "\n",
    "encoder_y = Conv1D(filters=40,kernel_size=3,activation='tanh')(encoder_input)\n",
    "encoder_y = GlobalMaxPool1D()(encoder_y)\n",
    "\n",
    "encoded = concatenate([encoder_x,encoder_y])\n",
    "encoded = Dropout(0.7)(encoded)\n",
    "encoded = Dense(80, activation='tanh')(encoded)#Relu and selu\n",
    "encoded = Dropout(0.7)(encoded)\n",
    "encoded = Dense(40, activation='tanh')(encoded)#Relu and selu\n",
    "predictions = Dense(1, activation='sigmoid')(encoded)#Relu and selu\n",
    "predictor = Model(encoder_input,predictions)\n",
    "\n",
    "predictor.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#print(predictor.summary())\n",
    "\n",
    "checkpoint_name = 'TEDS_Predictor_RUL.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictor.fit(LSTM_x_train, temp_LSTM_y_train, epochs=500, batch_size=512, shuffle=True, validation_split=0.33, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our weights, and we measure the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'weights/TEDS_Predictor_RUL.hdf5' # choose the best checkpoint few features\n",
    "predictor.load_weights(weights_file) # load it\n",
    "predictor.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred = target_scaler.inverse_transform(predictor.predict(LSTM_x_train))\n",
    "predictions = [i[0] for i in temp_pred]\n",
    "print('Train:',mean_absolute_error(LSTM_y_train,predictions),mean_squared_error(LSTM_y_train,predictions),sqrt(mean_squared_error(LSTM_y_train,predictions)))\n",
    "print(r2_score(LSTM_y_train,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred = target_scaler.inverse_transform(predictor.predict(LSTM_x_test))\n",
    "predictions = [i[0] for i in temp_pred]\n",
    "print('Test:',mean_absolute_error(LSTM_y_test,predictions),mean_squared_error(LSTM_y_test,predictions),sqrt(mean_squared_error(LSTM_y_test,predictions)))\n",
    "print(r2_score(LSTM_y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have to extract the encoder from our predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input=predictor.input, output=[predictor.layers[-2].output])\n",
    "encoder.trainable = False\n",
    "encoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to extract for all instances, their encoded representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_LSTM_x_train = encoder.predict(LSTM_x_train)\n",
    "encoded_LSTM_x_test = encoder.predict(LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by that, we build the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoded_LSTM_x_train[0].shape))\n",
    "decoded = Dense(120, activation='tanh')(encoded_input)\n",
    "decoded = Dropout(0.5)(decoded)\n",
    "\n",
    "decoded_y = RepeatVector(54)(decoded)\n",
    "decoded_y = Conv1D(filters=50,kernel_size=5,activation='tanh')(decoded_y)\n",
    "\n",
    "decoded_x = RepeatVector(50)(decoded)\n",
    "decoded_x = LSTM(units=80, return_sequences=True, activation='tanh')(decoded_x)\n",
    "decoded_x = Dropout(0.5)(decoded_x)\n",
    "decoded_x = LSTM(units=50, return_sequences=True, activation='tanh')(decoded_x)\n",
    "\n",
    "decoded = concatenate([decoded_x,decoded_y])\n",
    "decoded = LSTM(50, return_sequences=True, activation='sigmoid')(decoded)\n",
    "decoded = Dropout(0.5)(decoded)\n",
    "decoded = LSTM(14, return_sequences=True, activation='sigmoid')(decoded)\n",
    "\n",
    "decoder = Model(encoded_input,decoded)\n",
    "\n",
    "decoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])\n",
    "#print(decoder.summary())\n",
    "\n",
    "checkpoint_name = 'TEDS_Decoder_RUL.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder.fit(encoded_LSTM_x_train, LSTM_x_train, epochs=100, batch_size=2048, shuffle=True, validation_split=0.2, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'weights/TEDS_Decoder_RUL.hdf5' # choose the best checkpoint few features\n",
    "decoder.load_weights(weights_file) # load it\n",
    "decoder.compile(optimizer=\"adam\",loss=[root_mean_squared_error],metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse, mae, mse\n",
    "decoder.evaluate(encoded_LSTM_x_train,LSTM_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.evaluate(encoded_LSTM_x_test,LSTM_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LioNets Experiments\n",
    "Having everything setted up, we are now ready to try our methodology. We first initialize LioNets. LioNets requires a predictor (the regressor itself), an encoder (extracted from the predictor), a decoder, as well as some data (for best results the training data, in order to push the neighbourhood generation through known distribution for the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lionet = LioNets(predictor, decoder, encoder, LSTM_x_train, double_detector=False)\n",
    "transparent_model = Ridge(alpha=200,fit_intercept=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "train = np.array(random.sample(LSTM_x_train.tolist(),200))\n",
    "valid = np.array(random.sample(LSTM_x_test.tolist(),200))\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the fidelity of Lime and LioNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_predict(instance):\n",
    "    t_instance = np.array([instance]).reshape((len(instance),50,14))\n",
    "    a = predictor.predict(t_instance)\n",
    "    a = np.array([ii[0] for ii in a]) \n",
    "    return a\n",
    "explainer = LimeTabularExplainer(training_data=train.reshape(((len(train), 700))), \n",
    "                 discretize_continuous=False,\n",
    "                 mode=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_lime(instance):\n",
    "    t_instance = instance.reshape((700))\n",
    "    explanation = explainer.explain_instance(t_instance, predict_fn=lime_predict, num_features=700)\n",
    "    local_pred = explanation.local_pred[0]\n",
    "    return local_pred #This is because lime interprets class with label 1\n",
    "def fi_lionets(instance):\n",
    "    weights, res, loc_res = lionet.explain_instance(instance,3000,transparent_model)\n",
    "    return loc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluation(predictor.predict,None,lambda x: x,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity = evaluator.fidelity(train, [fi_lime, fi_lionets], class_n=0)\n",
    "print(\"Train:\")\n",
    "print('  Lime fidelity:', fidelity[0][0])\n",
    "print('  LioNets fidelity:', fidelity[1][0])\n",
    "fidelity = evaluator.fidelity(valid, [fi_lime, fi_lionets], class_n=0)\n",
    "print(\"Valid:\")\n",
    "print('  Lime fidelity:', fidelity[0][0])\n",
    "print('  LioNets fidelity:', fidelity[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate non zero weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = iutils.to_list(predictor.outputs)\n",
    "softmax_found = False\n",
    "ret = []\n",
    "for x in Xs:\n",
    "    layer, node_index, tensor_index = x._keras_history\n",
    "    if checks.contains_activation(layer, activation=\"sigmoid\"):\n",
    "        softmax_found = True\n",
    "        if isinstance(layer, keras.layers.Activation):\n",
    "            ret.append(layer.get_input_at(node_index))\n",
    "        else:\n",
    "            layer_wo_act = innvestigate.utils.keras.graph.copy_layer_wo_activation(layer)\n",
    "            ret.append(layer_wo_act(layer.get_input_at(node_index)))\n",
    "model2 = Model(input=predictor.input, output=ret)\n",
    "model2.trainable = False\n",
    "model2.compile(optimizer=\"adam\",loss=['binary_crossentropy'],metrics=['accuracy'])\n",
    "analyzer = innvestigate.create_analyzer('input_t_gradient',model2) #, low=0, high=1 on deep taylor bounded\n",
    "analyzerLRP = innvestigate.create_analyzer('lrp.epsilon',model2) #, low=0, high=1 on deep taylor bounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_GxI(instance):\n",
    "    ooo = analyzer.analyze(np.array([instance]))[0]\n",
    "    return [ooo][0].reshape((700))\n",
    "def fi_LRP(instance):\n",
    "    ooo = analyzerLRP.analyze(np.array([instance]))[0]\n",
    "    ooo = ooo*instance #only on lrp\n",
    "    return [ooo][0].reshape((700))\n",
    "def fi_lime(instance):\n",
    "    t_instance = instance.reshape((700))\n",
    "    explanation = explainer.explain_instance(t_instance, predict_fn=lime_predict, num_features=700)\n",
    "    weights = OrderedDict(explanation.as_list())\n",
    "    lime_w = dict(sorted(zip(list([int(wk) for wk in weights.keys()]), list(weights.values()))))\n",
    "    return np.array([lime_w[o] for o in lime_w.keys()]) #This is because lime interprets class with label 1\n",
    "def fi_lionets(instance):\n",
    "    weights, res, loc_res = lionet.explain_instance(instance,3000,transparent_model)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero = evaluator.non_zero_weights(train, [fi_GxI, fi_LRP, fi_lime, fi_lionets])\n",
    "print(\"Train:\")\n",
    "print('  GxI Non Zero:', non_zero[0][0])\n",
    "print('  LRP Non Zero:', non_zero[1][0])\n",
    "print('  Lime Non Zero:', non_zero[2][0])\n",
    "print('  LioNets Non Zero:', non_zero[3][0])\n",
    "non_zero = evaluator.non_zero_weights(valid, [fi_GxI, fi_LRP, fi_lime, fi_lionets])\n",
    "print(\"Valid:\")\n",
    "print('  GxI Non Zero:', non_zero[0][0])\n",
    "print('  LRP Non Zero:', non_zero[1][0])\n",
    "print('  Lime Non Zero:', non_zero[2][0])\n",
    "print('  LioNets Non Zero:', non_zero[3][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness = evaluator.robustness(train,[fi_lime, fi_GxI, fi_LRP, fi_lionets],None, [700,[50,14]])\n",
    "print(\"Train\")\n",
    "print('  Lime Robustness:', robustness[0])\n",
    "print('  GxI Robustness:', robustness[1])\n",
    "print('  LRP Robustness:', robustness[2])\n",
    "print('  LioNets Robustness:', robustness[3])\n",
    "robustness = evaluator.robustness(valid,[fi_lime, fi_GxI, fi_LRP, fi_lionets],None, [700,[50,14]])\n",
    "print(\"Valid:\")\n",
    "print('  Lime Robustness:', robustness[0])\n",
    "print('  GxI Robustness:', robustness[1])\n",
    "print('  LRP Robustness:', robustness[2])\n",
    "print('  LioNets Robustness:', robustness[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altruist Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_GxI(instance, prediction, model):\n",
    "    ooo = analyzer.analyze(np.array([instance.reshape((50,14))]))[0]    \n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(ooo[:,i:i+1].mean())\n",
    "    return np.array(weights)\n",
    "def fi_LRP(instance, prediction, model):\n",
    "    ooo = analyzerLRP.analyze(np.array([instance.reshape((50,14))]))[0]\n",
    "    ooo = ooo*instance.reshape((50,14)) #only on lrp\n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(ooo[:,i:i+1].mean())\n",
    "    return np.array(weights)\n",
    "def fi_lime(instance, prediction, model):\n",
    "    explanation = explainer.explain_instance(instance, predict_fn=lime_predict, num_features=700)\n",
    "    weights = OrderedDict(explanation.as_list())\n",
    "    lime_w = dict(sorted(zip(list([int(wk) for wk in weights.keys()]), list(weights.values()))))\n",
    "    lweights = np.array([lime_w[o] for o in lime_w.keys()]).reshape((50,14))\n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(lweights[:,i:i+1].mean())\n",
    "    return np.array(weights)\n",
    "def fi_lionets(instance, prediction, model):\n",
    "    weights, res, loc_res = lionet.explain_instance(instance.reshape((50,14)),3000,transparent_model)\n",
    "    lweights = weights.reshape((50,14))\n",
    "    weights = []\n",
    "    for i in range(14):\n",
    "        weights.append(lweights[:,i:i+1].mean())\n",
    "    return np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*Please let it run, it will take time probably*\")\n",
    "fi_names = {fi_GxI:'GxI',fi_LRP:'LRP',fi_lime:'Lime',fi_lionets:'LioNets'}\n",
    "fis = [fi_GxI, fi_LRP, fi_lime,fi_lionets]\n",
    "fis_scores = []\n",
    "for i in fis:\n",
    "    fis_scores.append([])\n",
    "count = 0\n",
    "feature_names = [i for i in range(14)]\n",
    "X_t = np.array([inst.reshape((700)) for inst in train])\n",
    "for instance in X_t:\n",
    "    if (count + 1) % 50 == 0:\n",
    "        print(count+1,\"/\",len(train),\"..\",end=\", \")\n",
    "    #print(len(instance))\n",
    "    count = count + 1\n",
    "    altruistino = Altruist(predictor, X_t, fis, feature_names, None, True,[50,14])\n",
    "    untruthful_features = altruistino.find_untruthful_features(instance)\n",
    "    for i in range(len(untruthful_features[0])):\n",
    "        fis_scores[i].append(len(untruthful_features[0][i]))\n",
    "count = 0\n",
    "print()\n",
    "print(\"Train:\")\n",
    "for fis_score in fis_scores:\n",
    "    fi = fis[count]\n",
    "    count = count + 1\n",
    "    print(' ',fi_names[fi],np.array(fis_score).mean())\n",
    "fi_matrix = np.array(fis_scores)\n",
    "count = 0\n",
    "fi_all = []\n",
    "for instance in X_t:\n",
    "    fi_all.append(fi_matrix[:,count].min())\n",
    "    count = count + 1\n",
    "print(\"Altogether:\",np.array(fi_all).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*Please let it run, it will take time probably*\")\n",
    "fi_names = {fi_GxI:'GxI',fi_LRP:'LRP',fi_lime:'Lime',fi_lionets:'LioNets'}\n",
    "fis = [fi_GxI, fi_LRP, fi_lime,fi_lionets]\n",
    "fis_scores = []\n",
    "for i in fis:\n",
    "    fis_scores.append([])\n",
    "count = 0\n",
    "feature_names = [i for i in range(14)]\n",
    "X_v = np.array([inst.reshape((700)) for inst in valid])\n",
    "for instance in X_v[:2]:\n",
    "    if (count + 1) % 50 == 0:\n",
    "        print(count+1,\"/\",len(train),\"..\",end=\", \")\n",
    "    #print(len(instance))\n",
    "    count = count + 1\n",
    "    altruistino = Altruist(predictor, X_t, fis, feature_names, None, True,[50,14])\n",
    "    untruthful_features = altruistino.find_untruthful_features(instance)\n",
    "    for i in range(len(untruthful_features[0])):\n",
    "        fis_scores[i].append(len(untruthful_features[0][i]))\n",
    "count = 0\n",
    "print()\n",
    "print(\"Valid:\")\n",
    "for fis_score in fis_scores:\n",
    "    fi = fis[count]\n",
    "    count = count + 1\n",
    "    print(' ',fi_names[fi],np.array(fis_score).mean())\n",
    "fi_matrix = np.array(fis_scores)\n",
    "count = 0\n",
    "fi_all = []\n",
    "for instance in X_t:\n",
    "    fi_all.append(fi_matrix[:,count].min())\n",
    "    count = count + 1\n",
    "print(\"Altogether:\",np.array(fi_all).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Experiments\n",
    "For a given example, its prediction and its interpretation, we would like to enhance it's RUL value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_instance = LSTM_x_train[112].copy()\n",
    "model = Ridge(alpha=200,fit_intercept=True,random_state=0)\n",
    "weights, real_prediction, local_prediction = lionet.explain_instance(temp_instance,3000,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Real prediction: \" + str(real_prediction)[:7] + \", Local prediction: \" + str(local_prediction)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scaler.inverse_transform(np.array([[0.08028],[0.08079]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to increase the RUL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From LioNets we acquired the weights of each sensor's measurements. Then we extract some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_all = {}\n",
    "count = 0\n",
    "for j in range(50):\n",
    "    count2 = 0\n",
    "    for i in sensors:\n",
    "        sensors_all.setdefault(i,[]).append([j, weights[count+count2], temp_instance[j][count2],\n",
    "                                             weights[count+count2]*temp_instance[j][count2]])\n",
    "        count2 = count2 + 1\n",
    "    count = count + 14\n",
    "sensors_std = []\n",
    "sensors_mean = []\n",
    "sensors_max = []\n",
    "sensors_min = []\n",
    "for i in sensors_all:\n",
    "    naa = np.array(sensors_all[i])[:,3]\n",
    "    sensors_std.append(naa.std())\n",
    "    sensors_mean.append(naa.mean())\n",
    "    sensors_max.append(naa.max())\n",
    "    sensors_min.append(naa.min())\n",
    "    #print(i, naa.mean(), naa.std(), naa.max(), naa.min())\n",
    "statistics = pd.DataFrame({\"Sensor\": list(sensors), \"Mean\": list(sensors_mean), \"STD\": list(sensors_std), \n",
    "                           \"Max\": list(sensors_max), \"Min\": list(sensors_min), \n",
    "                           \"Max-Min\": np.array(sensors_max) + np.array(sensors_min)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_vis = [i[2:] for i in sensors]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4), dpi=200)\n",
    "sns.barplot(to_vis,sensors_mean,ax=axs[0])\n",
    "axs[0].set_title('Mean')\n",
    "sns.barplot(to_vis,sensors_std,ax=axs[1])\n",
    "axs[1].set_title('STD')\n",
    "sns.barplot(to_vis,sensors_max,ax=axs[2])\n",
    "sns.barplot(to_vis,sensors_min,ax=axs[2])\n",
    "axs[2].set_title('Max and Min')\n",
    "fig.suptitle('Sensor Importance Statistics')\n",
    "plt.show()\n",
    "\n",
    "def plot_sensor(sens_i=1):\n",
    "    plt.figure(figsize=(14, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "    plt.subplot(131)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,1])\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,1].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence\"))\n",
    "    plt.subplot(132)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,2],color='g')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,2].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" value\"))\n",
    "    plt.subplot(133)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,3],color='r')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,3].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence * value\"))\n",
    "    plt.show()\n",
    "inter=interactive(plot_sensor \n",
    "   , sens_i=(1,14))\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the measurements from the s_12 sensor (number 8), which is is influencing negatively the RUL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = 3-1\n",
    "for i in range(35,50):\n",
    "    if weights.reshape(50,14)[i:i+1,sens:sens+1][0] < -0.0005:\n",
    "        temp_instance[i:i+1,sens:sens+1][0]=temp_instance[i:i+1,sens:sens+1][0]-0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the modified instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, real_prediction, local_prediction = lionet.explain_instance(temp_instance,3000,model)\n",
    "weights = weights * temp_instance.reshape(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Real prediction: \" + str(real_prediction)[:7] + \", Local prediction: \" + str(local_prediction)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scaler.inverse_transform(np.array([[0.10759],[0.10512]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to increase the RUL, a little. (Try and modify s_07 as well with the 12th sensor). How much does the RUL increased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_all = {}\n",
    "count = 0\n",
    "for j in range(50):\n",
    "    count2 = 0\n",
    "    for i in sensors:\n",
    "        sensors_all.setdefault(i,[]).append([j, weights[count+count2], temp_instance[j][count2],\n",
    "                                             weights[count+count2]*temp_instance[j][count2]])\n",
    "        count2 = count2 + 1\n",
    "    count = count + 14\n",
    "sensors_std = []\n",
    "sensors_mean = []\n",
    "sensors_max = []\n",
    "sensors_min = []\n",
    "for i in sensors_all:\n",
    "    naa = np.array(sensors_all[i])[:,3]\n",
    "    sensors_std.append(naa.std())\n",
    "    sensors_mean.append(naa.mean())\n",
    "    sensors_max.append(naa.max())\n",
    "    sensors_min.append(naa.min())\n",
    "    #print(i, naa.mean(), naa.std(), naa.max(), naa.min())\n",
    "statistics = pd.DataFrame({\"Sensor\": list(sensors), \"Mean\": list(sensors_mean), \"STD\": list(sensors_std), \n",
    "                           \"Max\": list(sensors_max), \"Min\": list(sensors_min), \n",
    "                           \"Max-Min\": np.array(sensors_max) + np.array(sensors_min)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vis = [i[2:] for i in sensors]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4), dpi=200)\n",
    "sns.barplot(to_vis,sensors_mean,ax=axs[0])\n",
    "axs[0].set_title('Mean')\n",
    "sns.barplot(to_vis,sensors_std,ax=axs[1])\n",
    "axs[1].set_title('STD')\n",
    "sns.barplot(to_vis,sensors_max,ax=axs[2])\n",
    "sns.barplot(to_vis,sensors_min,ax=axs[2])\n",
    "axs[2].set_title('Max and Min')\n",
    "fig.suptitle('Sensor Importance Statistics')\n",
    "plt.show()\n",
    "\n",
    "def plot_sensor(sens_i=1):\n",
    "    plt.figure(figsize=(14, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "    plt.subplot(131)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,1])\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,1].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence\"))\n",
    "    plt.subplot(132)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,2],color='g')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,2].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" value\"))\n",
    "    plt.subplot(133)\n",
    "    sns.lineplot(np.array(sensors_all['s_02'])[:,0],np.array(sensors_all[sensors[sens_i-1]])[:,3],color='r')\n",
    "    plt.hlines(y=np.array(sensors_all[sensors[sens_i-1]])[:,3].mean(), xmin=0, xmax=50, label='mean')\n",
    "    plt.title(str(\"Sensor\\'s \" + sensors[sens_i-1] + \" influence * value\"))\n",
    "    plt.show()\n",
    "inter=interactive(plot_sensor \n",
    "   , sens_i=(1,14))\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try for another instance, and play with the plots :) Thanks for using LioNets.\n",
    "\n",
    "For any question contact us at GitHub repo: https://github.com/intelligence-csd-auth-gr/LionLearn.git\n",
    "\n",
    "or at our lab's website: https://intelligence.csd.auth.gr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
